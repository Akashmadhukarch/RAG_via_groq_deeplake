{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef607bca-caff-4d6c-a08c-a2a24e83fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \\\n",
    "langchain \\\n",
    "langchain-community \\\n",
    "langchain-groq \\\n",
    "langchain-text-splitters \\\n",
    "deeplake \\\n",
    "sentence-transformers \\\n",
    "tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ded70b-e779-435e-bdd7-477146d91e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports working ✅\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DeepLake\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"All imports working ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22255ed6-a02b-4925-b387-61acf92cbbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement activeloop (from versions: none)\n",
      "ERROR: No matching distribution found for activeloop\n"
     ]
    }
   ],
   "source": [
    "!pip install -q activeloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5ca4d7-d971-47b5-b6b6-bf49927f8c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeplake in .\\langchain_env\\lib\\site-packages (3.9.52)\n",
      "Requirement already satisfied: numpy in .\\langchain_env\\lib\\site-packages (from deeplake) (1.26.4)\n",
      "Requirement already satisfied: pillow~=10.4.0 in .\\langchain_env\\lib\\site-packages (from deeplake) (10.4.0)\n",
      "Requirement already satisfied: boto3 in .\\langchain_env\\lib\\site-packages (from deeplake) (1.42.49)\n",
      "Requirement already satisfied: click in .\\langchain_env\\lib\\site-packages (from deeplake) (8.3.1)\n",
      "Requirement already satisfied: six~=1.16.0 in .\\langchain_env\\lib\\site-packages (from deeplake) (1.16.0)\n",
      "Requirement already satisfied: pathos in .\\langchain_env\\lib\\site-packages (from deeplake) (0.3.5)\n",
      "Requirement already satisfied: humbug>=0.3.1 in .\\langchain_env\\lib\\site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: tqdm in .\\langchain_env\\lib\\site-packages (from deeplake) (4.67.3)\n",
      "Requirement already satisfied: lz4 in .\\langchain_env\\lib\\site-packages (from deeplake) (4.4.5)\n",
      "Requirement already satisfied: pyjwt in .\\langchain_env\\lib\\site-packages (from deeplake) (2.11.0)\n",
      "Requirement already satisfied: pydantic in .\\langchain_env\\lib\\site-packages (from deeplake) (2.12.5)\n",
      "Requirement already satisfied: requests in .\\langchain_env\\lib\\site-packages (from humbug>=0.3.1->deeplake) (2.32.5)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.49 in .\\langchain_env\\lib\\site-packages (from boto3->deeplake) (1.42.49)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in .\\langchain_env\\lib\\site-packages (from boto3->deeplake) (1.1.0)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in .\\langchain_env\\lib\\site-packages (from boto3->deeplake) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in .\\langchain_env\\lib\\site-packages (from botocore<1.43.0,>=1.42.49->boto3->deeplake) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in .\\langchain_env\\lib\\site-packages (from botocore<1.43.0,>=1.42.49->boto3->deeplake) (2.6.3)\n",
      "Requirement already satisfied: colorama in .\\langchain_env\\lib\\site-packages (from click->deeplake) (0.4.6)\n",
      "Requirement already satisfied: ppft>=1.7.8 in .\\langchain_env\\lib\\site-packages (from pathos->deeplake) (1.7.8)\n",
      "Requirement already satisfied: dill>=0.4.1 in .\\langchain_env\\lib\\site-packages (from pathos->deeplake) (0.4.1)\n",
      "Requirement already satisfied: pox>=0.3.7 in .\\langchain_env\\lib\\site-packages (from pathos->deeplake) (0.3.7)\n",
      "Requirement already satisfied: multiprocess>=0.70.19 in .\\langchain_env\\lib\\site-packages (from pathos->deeplake) (0.70.19)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\langchain_env\\lib\\site-packages (from pydantic->deeplake) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in .\\langchain_env\\lib\\site-packages (from pydantic->deeplake) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in .\\langchain_env\\lib\\site-packages (from pydantic->deeplake) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\langchain_env\\lib\\site-packages (from pydantic->deeplake) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\langchain_env\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\langchain_env\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\langchain_env\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea8189-cbb3-44c9-942d-a8c74458a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f11be0c-1496-419b-ab52-b4f0b872d44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffd7072fe2d4134bd71d7a491444a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 1 embeddings in 1 batches of size 1:: 100%|█████████████████████████████████████| 1/1 [00:23<00:00, 23.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://chalamalasettyakashmadhukar/groq_rag_demo', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype     shape     dtype  compression\n",
      "  -------    -------   -------   -------  ------- \n",
      "   text       text      (1, 1)     str     None   \n",
      " metadata     json      (1, 1)     str     None   \n",
      " embedding  embedding  (1, 384)  float32   None   \n",
      "    id        text      (1, 1)     str     None   \n",
      "Deep Lake dataset created successfully ✅\n",
      "\n",
      "Answer:\n",
      "\n",
      "Google is competing with OpenAI by opening access to its AI language model PaLM and launching APIs and enterprise AI tools, aiming to rival OpenAI's GPT models.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Imports\n",
    "# ================================\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import DeepLake\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 1: Create Sample Text File\n",
    "# ================================\n",
    "\n",
    "text = \"\"\"\n",
    "Google is opening access to its AI language model PaLM.\n",
    "It aims to compete with OpenAI's GPT models.\n",
    "Google is launching APIs and enterprise AI tools.\n",
    "PaLM is a large language model similar to GPT.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"my_file.txt\", \"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 2: Load Document\n",
    "# ================================\n",
    "\n",
    "loader = TextLoader(\"my_file.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 3: Split Text into Chunks\n",
    "# ================================\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 4: Create Embeddings\n",
    "# ================================\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 5: Create Deep Lake Dataset\n",
    "# ================================\n",
    "\n",
    "dataset_path = \"hub://chalamalasettyakashmadhukar/groq_rag_demo\"\n",
    "\n",
    "db = DeepLake(\n",
    "    dataset_path=dataset_path,\n",
    "    embedding=embeddings,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "db.add_documents(docs)\n",
    "\n",
    "print(\"Deep Lake dataset created successfully ✅\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 6: Create Retriever\n",
    "# ================================\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 7: Create Groq LLM\n",
    "# ================================\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 8: Create Prompt Template\n",
    "# ================================\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question using only the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 9: Build Modern RAG Chain\n",
    "# ================================\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Step 10: Ask Question\n",
    "# ================================\n",
    "\n",
    "query = \"How is Google competing with OpenAI?\"\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "print(\"\\nAnswer:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf23f7-e5b6-4653-842c-ac7e371c59b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
